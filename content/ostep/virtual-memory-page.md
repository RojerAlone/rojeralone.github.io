---
title: "OSTEP 读书笔记: 内存虚拟化之内存页"
date: 2021-07-11T22:17:40+08:00
draft: false

categories:
- 读书笔记
tags:
- ostep
- 操作系统
---

如果将内存以定长的分页管理，那么就能解决分段管理内存的碎片化问题，并且管理空闲内存也更方便，只需要一个空闲 page 列表，需要多大内存就分配相应个数的 page 就可以了。

为了简化虚拟内存到物理内存的映射关系，分页的大小是固定的，虚拟内存和物理内存都使用相同大小的分页。

操作系统使用页表（**page table**) 来表示虚拟内存到物理内存的映射，并且每个进程都有自己的页表。

每个虚拟内存页都有一个编号来表示，称为 **VPN** (Vitrual Page Number)，而物理内存页的编号为 **PFN** (Physical Frame Number) 或者 **PPN** (Physical Page Number)。

为了知道访问的虚拟内存是哪个页，虚拟地址需要耗费几个 bit 来表示，比如高 2 位表示 VPN，剩下的表示在内存页内的偏移量，操作系统只需要查找页表中对应的 VPN 映射的 PPN，然后访问指定偏移量的内存就行了。

## 页表存储

假设在 32-bit 的系统上，page 大小为 4K，那么一个进程的地址空间为 4GB，有 1M 个 page，每个 page 的数据结构 **PTE** (Page Table Entry) 需要 4 byte，那么每个进程需要 4MB 的内存来保存页表，1000 个进程就需要 4GB 的内存。

由于页表太大了，没法直接在 MMU 中存储，只能放在内存里(也可以放在磁盘)，那么现在的问题就是解决页表的存储问题，既要减少内存使用，又要高效查找映射关系。

PTE 中有什么？

-   valid bit：有效位，内存是否已经分配给进程了，没分配的不能访问
-   protection bit：保护位，是否可读 / 可写 / 可执行
-   persent bit：持久位，是否已经置换到磁盘上了
-   dirty bit：从磁盘加载到内存以后是否被修改过，没修改的话下次置换它就不用写磁盘了
-   access bit：记录访问信息，用来决定是否是热点数据，能不能被置换掉
-   ...

另一个问题就是效率，如果要访问内存，操作系统本身要解析虚拟地址对应的 VPN，然后访问页表，找到映射关系，也就是寻址这个操作中不是一步完成的，还需要另一次寻址。

## TLB

TLB (translation-lookaside buffer) 是 MMU 芯片的一部分，可以看做是 VPN 到 PFN 映射关系的硬件级别缓存，用来加速地址转换，更贴切的名字是 address-translation cache，TLB 只是历史原因。

TLB 命中映射关系，能够极大降低访问内存的耗时，它的位置离 CPU 核很近，并且特意设计，使得访问很快，TLB missing 将会降低性能，毕竟访问内存相比于 CPU 指令的执行太慢了，正是 TLB 的存在，使得虚拟内存真正高效。

### 谁来处理 TLB Missing

两种选择，硬件或者操作系统，以前的 CISC (complex instruction sets computer) 复杂指令集计算机使用硬件来处理，它提供了足够复杂 的指令，而现代的计算机使用 SISC (reduced instruction sets computer) 精简指令集，由操作系统来处理。

SISC 遇到 TLB Missing 将会抛出异常，操作系统来处理异常，查找页表然后用特权指令写入 TLB，然后返回，硬件重新执行中断的指令。

需要注意的是，硬件从中断返回以后，不是像普通进程那样直接继续执行，而是要回到中断前的指令，因此需要特殊地修改 PC。另外一点是，既然已经遇到了 TLB Missing，操作系统去查页表的时候，会再次遇到 TLB，然后死循环了，解决方式是操作系统直接把页表放在物理内存里，这样就不需要 TLB 了，或者直接将页表这块内存的映射关系永久(操作系统运行期间)保存在 TLB 中，这样就一直能够命中。

操作系统处理 TLB Missing 的优势是灵活性，可以以任意高效的数据结构来查询页表，不需要适配硬件，另一个优势是简化的硬件的逻辑，使硬件足够简单。

### TLB 中的内容

除了 VPN 和 PFN 的映射外，还有其他的一些数据，TLB 既然是转换关系的缓存，那么最好直接放页表中的 entry，即 PTE 的内容，valid bit / protection bit / dirty bit 等，另外还有 address-space identifier，下面会说到这个东西。

### 上下文切换时 TLB 的行为

当上下文切换时，TLB 中的地址空间就换成了另一个进程的，那么一定会 cache miss，为了解决这个问题，加入了 **ASID** (address-space identifier)，用来标识映射关系所属的地址空间。当然 TLB 内的空间也不是无限的，就像普通的缓存一样，也要有置换策略，比如 LRU，但是 LRU 的问题在于如果进程执行的是循环读取数组之类的，那么 LRU 可能没什么意义(读取 n+1 的数据，但是 TLB 中只有 n 个映射对)，另一种策略是随机置换，实现比较简单。

## 多级页表

为了解决页表占用内存过大的问题，采用多级页表的机制。

page directory 可以理解为页表的目录项，先找到虚拟地址对应的 page directory，然后从 page directory 中找到其中一部分 page table， 如果一个 page directory 中没有任何实际分配的映射关系，那么这个 page directory 就不需要分配内存，能够极大节省内存。

另外，使用 page directory 以后，页表的数据结构不再是数组了，页表直接放在内存页中。

只有一级 page directory 也有问题，以 32 位 机器，page 大小 4K 为例，地址空间为 4GB，那么进程最多有 1M 个内存页，假设 PTE 大小为 4 byte，那么一个内存页能放置 1K 个 PTE，单个进程需要 1K 个页来存放页表，而 1K 个页的上一层 page directory 需要 4KB，正好一个内存页能放下。如果是 64 位机器呢？需要好多个 page directory，那么 page directory 又存在了 page table 浪费内存的问题。所以，解决方式是再加一层 page directory 的 page directory，也就是现代操作系统使用的多级页表（和 Colossus 解决元数据的问题有些相似，直接放在 BigTable 上，而 BigTable 又构建于 Colossus 之上）。

多级页表只是解决页表内存占用过多的一种方式，还有一种方式是翻转页表，不是 VPN -> PFN 的关系，而是 PFN -> (pid, VPN) 的关系，即只记录物理页中存放的数据是哪个进程的哪个虚拟页，但是缺点是需要遍历这个翻转页表，找到目标虚拟地址。

## 内存置换

解决了页表占用内存过多的问题以后，我们来解决最后一个问题，每个进程都有很大的地址空间，但是物理内存是有限的，如果给进程一个“实际”的假象，它确实能够申请到这么多内存？这就是内存置换技术。

在磁盘上有一块空间，当物理内存不够用的时候，将一些没有正在使用的内存页保存到磁盘上，当需要的时候，再从磁盘加载，虽然物理比较小，但是磁盘空间是很大的。

之前提到过 PTE （Page Table Entry) 中包含有一个 bit 叫做 present bit，现在用到了，这个位表示内存页是否存在于物理内存中，如果不存在，那么操作系统抛出一个缺页中断 (Page Fault)，此时缺页中断处理器去把 swap 空间的页取回到内存中。

为了避免访存时出现缺页执行 IO，操作系统会使用后台线程来提前置换内存页，当空闲内存页小于 low watermark 低水位时就启动线程开始将一些空闲内存页写入 swap 空间，大于 high watermark 高水位后停止。

### 置换策略

物理内存页可以看做是虚拟内存页的“缓存”，而置换策略的目标是，最大化缓存命中率。

-   最优策略：置换将来最远使用的 page，只是理想化的概念，实际上未来不可预知，这个策略只是一个对照的指标，实际的策略应当尽力接近这个指标
-   FIFO
-   Random
-   LRU：和调度策略一样，从历史的经验中学习到的东西才是有效的，通过一些测试，暴露出了 LRU 的致命问题：比如物理页有 49 个，虚拟页有 50 个，进程循环访问虚拟页，那么命中率一直是 0

#### Approximating LRU

近似 LRU，LRU 的问题是每次访问都需要记录访问时间，置换页的时候需要遍历所有物理页，找到最久未访问的页，操作太重量级了，那么近似 LRU 就是不置换“最久”未使用的，只是近似。每个物理页都有一个 bit 叫做 use bit 或者 reference bit，表示这个页最近访问过。

简单介绍了一种叫 clock 算法的策略，置换时从某个页面开始，如果这个页面的 use bit 是 0，那么置换它，否则置为 0 然后往下面继续找，直到找到 use bit 是  0 的页，最坏的情况就是遍历了所有的页。这只是一种通过 use bit 实现近似 LRU 的策略，其他通过定期重置 use bit 为 0 的策略也是可以实现的。即使它达不到 LRU 的命中率，也可以非常接近，并且避免了 LRU 的缺点。

另外，dirty bit 可以优化这个策略，因为 IO 是重量级操作，置换一个未被修改的页只需要内存操作就可以了，但是一个 dirty page 就需要写磁盘，因此优先置换非 dirty bit 是一个优化点。

#### 其他策略

其他策略包括预取，比如代码块很可能被批量执行，还有批量置换，这样写磁盘快点。

还有内存压力太大的时候该怎么办，可以直接停止一些内存密集型应用，或者干脆杀死它，但是可能会导致其他问题。

