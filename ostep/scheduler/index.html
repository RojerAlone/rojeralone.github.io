<!doctype html><html lang=en-us><head><title>OSTEP 读书笔记: 虚拟化之任务调度 // RojerAlone</title><link rel="shortcut icon" href=/favicon.ico><meta charset=utf-8><meta name=generator content="Hugo 0.81.0"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="RojerAlone"><meta name=description content><link rel=stylesheet href=https://rojeralone.cn/css/main.min.88e7083eff65effb7485b6e6f38d10afbec25093a6fac42d734ce9024d3defbd.css><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','G-T1VNZF1VBZ','auto'),ga('send','pageview'))</script><meta name=twitter:card content="summary"><meta name=twitter:title content="OSTEP 读书笔记: 虚拟化之任务调度"><meta name=twitter:description content="虚拟化之 CPU 虚拟化：任务调度 工作负载假设  任务运行时间相同 任务同时到达开始运行 任务开始运行不停止直到运行结束 所有任务只需要用 CPU 运行时间已知  调度指标 平均等待时间
调度策略  FIFO，放开假设 1，导致问题：耗时长的任务先运行，一些短任务要等很久 SJF（Shortest Job First）：解决 FIFO 的弊端，放开假设 2，长任务执行时短任务来了，也要等很久 STCF（Shortest Time-to-Completion First）：放开假设 3，允许中断，可以先完成的任务先执行  现在引入新的指标，响应时间，即任务开始运行的时间减去任务到达的时间，因为操作系统会有用户直接在控制台执行命令的场景，希望立马能够有响应而不是给人系统卡住的感觉。
Round Robin 算法，轮转执行，以时钟周期的整数倍为一个时间片，每个任务轮流执行一个时间片，这样能够降低响应时间，但是完成等待时间就上去了，鱼与熊掌不可兼得。  那么放开假设 4，任务需要执行 IO，策略变更为当任务执行 IO 时，让出 CPU 给需要的任务。
在真实的系统中，运行时间是很不确定的，很难预测，应该怎么处理？下面的多级反馈队列机制将会解决这个问题。
MLFQ MLFQ (Multiple-Level Feedback Queue) 的基本原理是有多个优先级队列，优先级更高的队列里的任务优先执行，优先级相同的就轮流执行，同时还会动态调整任务的优先级。
 Rule 1： A 的优先级大于 B，则 A 运行 Rule 2：A 优先级等于 B，A、B 使用 RR 运行 Rule 3：任务刚提交的时候，优先级默认为最高优先级 Rule 4a：任务运行时用光了一个完整的时间片，则降低优先级，因为它是 CPU 密集的，对响应时间不敏感 Rule 4b：用完时间片之前让出了 CPU，保持优先级不变  MLFQ 有几个问题：饥饿、投机、优先级只降不升"><meta property="og:title" content="OSTEP 读书笔记: 虚拟化之任务调度"><meta property="og:description" content="虚拟化之 CPU 虚拟化：任务调度 工作负载假设  任务运行时间相同 任务同时到达开始运行 任务开始运行不停止直到运行结束 所有任务只需要用 CPU 运行时间已知  调度指标 平均等待时间
调度策略  FIFO，放开假设 1，导致问题：耗时长的任务先运行，一些短任务要等很久 SJF（Shortest Job First）：解决 FIFO 的弊端，放开假设 2，长任务执行时短任务来了，也要等很久 STCF（Shortest Time-to-Completion First）：放开假设 3，允许中断，可以先完成的任务先执行  现在引入新的指标，响应时间，即任务开始运行的时间减去任务到达的时间，因为操作系统会有用户直接在控制台执行命令的场景，希望立马能够有响应而不是给人系统卡住的感觉。
Round Robin 算法，轮转执行，以时钟周期的整数倍为一个时间片，每个任务轮流执行一个时间片，这样能够降低响应时间，但是完成等待时间就上去了，鱼与熊掌不可兼得。  那么放开假设 4，任务需要执行 IO，策略变更为当任务执行 IO 时，让出 CPU 给需要的任务。
在真实的系统中，运行时间是很不确定的，很难预测，应该怎么处理？下面的多级反馈队列机制将会解决这个问题。
MLFQ MLFQ (Multiple-Level Feedback Queue) 的基本原理是有多个优先级队列，优先级更高的队列里的任务优先执行，优先级相同的就轮流执行，同时还会动态调整任务的优先级。
 Rule 1： A 的优先级大于 B，则 A 运行 Rule 2：A 优先级等于 B，A、B 使用 RR 运行 Rule 3：任务刚提交的时候，优先级默认为最高优先级 Rule 4a：任务运行时用光了一个完整的时间片，则降低优先级，因为它是 CPU 密集的，对响应时间不敏感 Rule 4b：用完时间片之前让出了 CPU，保持优先级不变  MLFQ 有几个问题：饥饿、投机、优先级只降不升"><meta property="og:type" content="article"><meta property="og:url" content="https://rojeralone.cn/ostep/scheduler/"><meta property="article:section" content="ostep"><meta property="article:published_time" content="2021-06-20T15:33:09+08:00"><meta property="article:modified_time" content="2021-06-20T15:33:09+08:00"></head><body><header class=app-header><a href=https://rojeralone.cn/><img class=app-header-avatar src=/avatar.jpg alt=RojerAlone></a><h1>RojerAlone</h1><p>Developer</p><div class=app-header-social><a href=https://github.com/RojerAlone target=_blank rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github"><title>Github</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></div></header><main class=app-container><article class=post><header class=post-header><h1 class=post-title>OSTEP 读书笔记: 虚拟化之任务调度</h1><div class=post-meta><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar"><title>calendar</title><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>Jun 20, 2021</div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock"><title>clock</title><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>2 min read</div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag"><title>tag</title><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg><a class=tag href=https://rojeralone.cn/tags/ostep/>ostep</a>
<a class=tag href=https://rojeralone.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/>操作系统</a></div></div></header><div class=post-content><h1 id=虚拟化之-cpu-虚拟化任务调度>虚拟化之 CPU 虚拟化：任务调度</h1><h2 id=工作负载假设>工作负载假设</h2><ol><li>任务运行时间相同</li><li>任务同时到达开始运行</li><li>任务开始运行不停止直到运行结束</li><li>所有任务只需要用 CPU</li><li>运行时间已知</li></ol><h2 id=调度指标>调度指标</h2><p>平均等待时间</p><h2 id=调度策略>调度策略</h2><ol><li>FIFO，放开假设 1，导致问题：耗时长的任务先运行，一些短任务要等很久</li><li>SJF（Shortest Job First）：解决 FIFO 的弊端，放开假设 2，长任务执行时短任务来了，也要等很久</li><li>STCF（Shortest Time-to-Completion First）：放开假设 3，允许中断，可以先完成的任务先执行</li></ol><p>现在引入新的指标，响应时间，即任务开始运行的时间减去任务到达的时间，因为操作系统会有用户直接在控制台执行命令的场景，希望立马能够有响应而不是给人系统卡住的感觉。</p><ol start=4><li>Round Robin 算法，轮转执行，以时钟周期的整数倍为一个时间片，每个任务轮流执行一个时间片，这样能够降低响应时间，但是完成等待时间就上去了，鱼与熊掌不可兼得。</li></ol><p>那么放开假设 4，任务需要执行 IO，策略变更为当任务执行 IO 时，让出 CPU 给需要的任务。</p><p>在真实的系统中，运行时间是很不确定的，很难预测，应该怎么处理？下面的多级反馈队列机制将会解决这个问题。</p><h2 id=mlfq>MLFQ</h2><p>MLFQ (Multiple-Level Feedback Queue) 的基本原理是有多个优先级队列，优先级更高的队列里的任务优先执行，优先级相同的就轮流执行，同时还会动态调整任务的优先级。</p><ul><li>Rule 1： A 的优先级大于 B，则 A 运行</li><li>Rule 2：A 优先级等于 B，A、B 使用 RR 运行</li><li>Rule 3：任务刚提交的时候，优先级默认为最高优先级</li><li>Rule 4a：任务运行时用光了一个完整的时间片，则降低优先级，因为它是 CPU 密集的，对响应时间不敏感</li><li>Rule 4b：用完时间片之前让出了 CPU，保持优先级不变</li></ul><p>MLFQ 有几个问题：饥饿、投机、优先级只降不升</p><ul><li>饥饿：如果很多交互任务，那么 CPU 密集的任务无法执行</li><li>投机：如果一个任务刻意在用完时间片之前放弃 CPU，那么就能一直在最高优先级</li><li>优先级只降不升：任务行为可能变化，从 CPU 密集变为交互型</li></ul><p>为了解决饥饿问题，我们引入新的机制，定期重置所有任务优先级为最高优先级，同时也解决了优先级只升不降的问题：</p><ul><li>Rule 5: 定期将所有任务移到优先级最高的队列里</li></ul><p>但是投机问题还没解决，回到上文，能够投机的前提是 Rule 4a/b，（个人认为像是投机倒把的人，对外表现的很好以致于分到了蛋糕，但是好好干活的人并没有得到应有的机会，这样是不好的），只关心了现在的表现而忽略了之前的行为，因此对其进行优化：</p><ul><li>Rule 4：一旦任务在某个优先级队列用尽了分给它的 CPU 时间，权重就下降，移到下一级队列中</li></ul><p>MLFQ 比之前提到的调度器都好，但是他的问题是有些参数化的配置，比如时间片大小、优先级队列的个数、定期重置优先级的周期，都需要经验判断以及持续的调优才行。</p><p><a href=https://en.wikipedia.org/wiki/Oracle_Solaris>Solaris 调度器</a>使用了一个表格来描述规则，比如优先级的队列个数，每个优先级队列内时间片大小。</p><p>FreeBSD 调度器使用公式来计算任务优先级，还有些调度器不开放最高优先级给用户任务，只给内核任务使用。</p><h2 id=比例份额调度>比例份额调度</h2><p>分配 CPU 按照比例来分布，保证每个任务使用确定比例的 CPU 时间。</p><p>第一种调度器是彩票调度，简单来说，每个任务都有若干张彩票，每个时间片抽奖，抽中哪张哪张在这个时间片运行，实现起来也比较简单，生成一个随机数，每个任务持有的彩票其实就是一个数字区间，生成的随机数落在这个区间这个任务就能运行，和权重负载均衡实现有些相似。</p><p>另外，彩票调度还允许彩票分配，比如不同的用户都有一些任务，用户给自己的任务分配彩票，调度系统会按照全局的彩票分配情况“抽奖”。</p><p>还支持彩票转义，一个任务可以把自己的票给另一个任务，比如客户端和服务端交互，客户端需要服务端帮自己做一些任务，那么提交任务的时候把彩票给服务端，服务端帮客户端完成后再返还给客户端。</p><p>最后，还可以实现彩票膨胀，在互相信任的系统里，一个任务可以临时提升自己拥有的彩票数来获得 cpu 时间，不需要和其他进程交流。</p><p>彩票调度的问题是，不够公平，因为抽奖是随机的，以两个任务完成的时间相除作为公平性的指标，通过实验，需要长时间运行后才能够趋向公平调度。另一个问题是如何分配彩票，交给提交任务的用户是可以的，但是这并不算一个解决方案，因为它啥也没说。</p><p>步长调度是优化上述彩票调度缺点的调度器，它不直接根据当前的抽奖结果决定谁来运行，和上述 MLFQ 调度器最终的优化策略一样，调度器应该考虑任务之前的表现，步长调度也是这样（根据后验知识来调度）。每个任务仍然持有一定数量的彩票，而引入一种新的概念，步长，步长是一个很大的值除以任务的彩票数得到的，比如 10000，任务 A 有 200 张彩票，那么它的步长是 50。引入步长以后，任务每运行一次，那么走过的步数加上它的步长。而每次调度抽奖不是看抽中谁了，而是看谁的总步数最短，那么谁该运行，成功地将之前的表现引入的调度器中，并且保持了彩票调度的基础概念，谁“买”的彩票多（步长小），谁的中奖概率大（步长小，走过的步数小，那么应该优先调度）。</p><p>看起来步长调度是完美的，但是有个很大的缺陷，它只有全局状态， 当一个新任务加入的时候，它的初始步数是 0，那么就会一直调度它，所以还是需要彩票调度的，彩票调度没有全局状态， 只关心当前的调度，不会偏向新任务。</p><p>第三种调度方式是 Linux 的 CFS(Completely Fair Scheduler，完全公平调度器) 。大多数调度器通过固定的时间片来分配 CPU 时间，但是 CFS 使用了 virtual runtime (vruntime) 来分配 CPU。随着任务的运行，它的 vruntime 增加，在大多数情况下，每个任务的 vruntime 以相同的速率提升，每次调度时，选择 vruntime 最小的任务来运行。</p><p>问题来了，CFS 怎么知道一个任务改运行多久（多久调度一次？因为它不直接依赖固定的时间片了）？如果频繁调度，会发生频繁的上下文切换，但是能保证公平；如果缓缓调度，减少了上下文切换，但是可能就不太公平了。CFS 通过多个控制参数来管理，第一个参数是 <strong>sched_latency</strong>，可以认为这个就是时间片，不过它不是固定的时间片。经典的 sched_latency 是 48ms，不过不是直接使用，而是用 sched_latency / processors，比如 CPU 上有 4 个任务，那么时间片就是 48 / 4 = 12ms。</p><p>如果有太多任务运行，时间片是不是就变小了，导致调度器频繁调度？是的，为了解决这个问题，又引入了一个新的参数，<strong>min_granularity</strong>，经典值是 6ms，CFS 保证一个任务运行的时间片不会小于这个值。</p><p>此外，CFS 还支持优先级，采用了经典的 UNIX <code>nice</code> 机制，nice 值的区间是 -20~+19，默认是 0，nice 值越低优先级越高。时间片也和 nice 值挂钩，实际上每个 nice 值都对应一个权重 weight，nice 值越低权重越高，<code>time_slice = (nice_weight / sum(weight)) * sched_latency</code>，可见权重越高，时间片也越长。另外，因为调度是通过 vruntime 来进行的，所以在这里 vruntime 的增长速率也和权重有关，<code>vruntime += (default_weight / nice_weight) * runtime</code>，默认的权重即是默认 nice 值 0 的权重 1024，可见权重越高，vruntime 增长的也越慢，这样就保证了优先调度。</p><p>CFS 使用红黑树保持了高效调度（面熟手写红黑树的梗在 Linus 这真的不适用啊），并且如果任务在 sleep 或者等待 IO，将会从红黑树中删除，但是仍然会跟踪任务的状态，可以调度的时候会重新加回来。问题来了，从树中移除以后再加回来，vruntime 落后了很多，如果不做处理就会一直调度这个任务（同时也是上面提到的步长调度的缺点，新任务加入），CFS 通过设置新加入任务 vruntime 为当前树中最小值来解决这个问题，因为树中只有正在运行的任务，所以当一个任务睡眠又醒来的时候，它的 vruntime 一定是比之前大了，但是实际上它并没有消耗 CPU，对它来说不太公平，尤其是经常睡眠的任务（个人认为还是比较公平的，因为每次加入调度的时候，优先级都是最高的）。</p></div><div class=post-footer></div></article></main></body></html>