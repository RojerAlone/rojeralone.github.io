<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ostep on RojerAlone</title><link>https://rojeralone.cn/tags/ostep/</link><description>Recent content in ostep on RojerAlone</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 21 Jun 2021 11:06:29 +0800</lastBuildDate><atom:link href="https://rojeralone.cn/tags/ostep/index.xml" rel="self" type="application/rss+xml"/><item><title>OSTEP 读书笔记: 虚拟化之多处理器任务调度</title><link>https://rojeralone.cn/ostep/multiprocessor-scheduler/</link><pubDate>Mon, 21 Jun 2021 11:06:29 +0800</pubDate><guid>https://rojeralone.cn/ostep/multiprocessor-scheduler/</guid><description>Multiprocessors Scheduling 之前讨论的都是单 CPU 上的多个任务调度，但是现代 CPU 大都是多核 CPU，多线程编程也随之出现，编程方式也和以前不一样，这里就讨论下多核调度策略。
多核带来的第一个问题是缓存的一致性问题， CPU 会缓存一些数据到 CPU 核中，多核情况下，一个任务从 A 核调度到了 B 核，那么在修改了值以后可能读到缓存的旧值，可以通过总线来解决，每个 CPU 核监听总线上的时间，当发现缓存数据对应的内存中数据变化时，标记脏数据或更新数据。
另一个问题是并发问题，最后一个问题是缓存亲缘性，一个任务最好一直在同一个 CPU 处理器上运行，这样就能使用之前的缓存了。
SQMS single-queue multiprocessor scheduling 的实现方式是将所有的任务都在同一个队列中，多处理器调度时都从这个队列中进行调度，优点是能够在之前提到的调度器上稍微修改就能运行。
缺点也很明显，多处理器消费一个队列，要加锁才能保证并发安全， 而当处理器核数很多的时候，性能就会变差。另一个问题是缓存亲缘性，这个问题也可以解决，通过忽略一些在其他处理器上运行的任务，但是实现起来比较复杂。
MQMS 很自然想到，一个任务队列有问题，那么多个任务队列呢？这就是 multi-queue multiprocessor scheduling。 它同时解决了并发和缓存亲缘性问题。
MQMS 的问题是负载均衡，当任务放到一个 CPU 核的队列内后不再变化，任务提交时任务的执行时间不可预测，会出现某个 CPU 的任务全部完成了，另一个 CPU 还要运行好久才能完成任务。
这时候就不得不放弃一些缓存亲缘性了，将一些等待执行的任务迁移到空闲的 CPU 上。一种实现机制是工作窃取，一个 CPU 上的调度器偶尔会偷看另一个 CPU 上的调度负载，如果发现另一个 CPU 比较繁忙而自己比较空闲，那么就“偷”一个或一些任务来运行。这里又有一个权衡，不能太频繁偷看，否则消耗太高，这又是一个调参找阈值的地方。
Linux Multiprocessor Schedulers Linux 的调度器没有采用统一的多队列，O(1) 和 CFS 调度器都采用了多队列，但是 BFS 调度器并没有，它采用了单队列。书中并没有详细说明这些调度器的策略，下面是维基的页面：
O(1) Scheduler BFS</description></item><item><title>OSTEP 读书笔记: 虚拟化之任务调度</title><link>https://rojeralone.cn/ostep/scheduler/</link><pubDate>Sun, 20 Jun 2021 15:33:09 +0800</pubDate><guid>https://rojeralone.cn/ostep/scheduler/</guid><description>虚拟化之 CPU 虚拟化：任务调度 工作负载假设 任务运行时间相同 任务同时到达开始运行 任务开始运行不停止直到运行结束 所有任务只需要用 CPU 运行时间已知 调度指标 平均等待时间
调度策略 FIFO，放开假设 1，导致问题：耗时长的任务先运行，一些短任务要等很久 SJF（Shortest Job First）：解决 FIFO 的弊端，放开假设 2，长任务执行时短任务来了，也要等很久 STCF（Shortest Time-to-Completion First）：放开假设 3，允许中断，可以先完成的任务先执行 现在引入新的指标，响应时间，即任务开始运行的时间减去任务到达的时间，因为操作系统会有用户直接在控制台执行命令的场景，希望立马能够有响应而不是给人系统卡住的感觉。
Round Robin 算法，轮转执行，以时钟周期的整数倍为一个时间片，每个任务轮流执行一个时间片，这样能够降低响应时间，但是完成等待时间就上去了，鱼与熊掌不可兼得。 那么放开假设 4，任务需要执行 IO，策略变更为当任务执行 IO 时，让出 CPU 给需要的任务。
在真实的系统中，运行时间是很不确定的，很难预测，应该怎么处理？下面的多级反馈队列机制将会解决这个问题。
MLFQ MLFQ (Multiple-Level Feedback Queue) 的基本原理是有多个优先级队列，优先级更高的队列里的任务优先执行，优先级相同的就轮流执行，同时还会动态调整任务的优先级。
Rule 1： A 的优先级大于 B，则 A 运行 Rule 2：A 优先级等于 B，A、B 使用 RR 运行 Rule 3：任务刚提交的时候，优先级默认为最高优先级 Rule 4a：任务运行时用光了一个完整的时间片，则降低优先级，因为它是 CPU 密集的，对响应时间不敏感 Rule 4b：用完时间片之前让出了 CPU，保持优先级不变 MLFQ 有几个问题：饥饿、投机、优先级只降不升</description></item></channel></rss>