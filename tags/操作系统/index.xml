<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>操作系统 on RojerAlone</title><link>https://rojeralone.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link><description>Recent content in 操作系统 on RojerAlone</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 23 Jun 2021 20:14:15 +0800</lastBuildDate><atom:link href="https://rojeralone.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml"/><item><title>内存虚拟化之基础知识</title><link>https://rojeralone.cn/ostep/virtual-memory-basic/</link><pubDate>Wed, 23 Jun 2021 20:14:15 +0800</pubDate><guid>https://rojeralone.cn/ostep/virtual-memory-basic/</guid><description>内存虚拟化 - 基础知识 地址空间 操作系统为虚拟内存提供的抽象叫做地址空间(Address Space)，是运行中的进程能够看到的内存空间。进程申请内存主要用作 3 种数据的存储：代码、堆、栈。每个进程看到的地址空间都是一样的，给进程一种自己拥有所有内存的假象，而在真正的物理内存上，实现了进程隔离，保证了内存操作的安全性。
目标 内存虚拟化的目标：
透明 高效 保护：进程之间不能互相访问对方的内存空间 内存操作 API 一个进程会显示申请两种类型的内存，栈和堆。栈内存由编译器隐式帮程序员申请了，并且在生命周期结束后隐式释放，如果要将该内存在生命周期之外使用，则要分配堆内存，内存管理主要关注堆内存。
malloc() void *malloc(size_t size) 申请大小为 size 的内存空间，返回指向这块内存空间的指针，一般使用类型转换转化为目标类型。size 一般使用 sizeof() 操作获取，因为在不同的平台上大小可能不一样，编译器会解析 sizeof() 的结果，而不是在运行时才解析。
free() 释放内存，把 malloc 返回的指针传进去就行，内存分配器会知道释放多少内存的，不需要显示传进去。
使用注意事项 未分配内存：一些函数的指针参数是非空指针，比如 strcpy 未分配足够的内存：还是 strcpy，报错与否是不确定的 未初始化申请的内存：里边的内容是不确定的 未释放申请的内存：导致内存泄漏 提前释放了还在使用的内存：野指针 / 悬浮指针 重复释放内存：不可预知的后果，大部分是崩溃 错误调用 free(): 释放了未知的内存 系统调用 malloc() 和 free() 并不是系统调用，而是内存分配库提供的功能，这些库的底层依赖了系统调用 brk 和 sbrk，程序员不应该直接调用这些方法，除非你很清楚你在做什么，另外还可以通过 mmap 来分配内存，这是个系统调用。
内存分配库还提供一些其他调用，比如 calloc() 分配全是 0 的内存，realloc() 传入一个内存指针，返回一个更大的但是已经将旧内存 copy 过去的新内存地址。
地址转换 内存的虚拟化和 CPU 的虚拟化追求的目标一致：效率和控制。</description></item><item><title>OSTEP 读书笔记: 虚拟化之多处理器任务调度</title><link>https://rojeralone.cn/ostep/multiprocessor-scheduler/</link><pubDate>Mon, 21 Jun 2021 11:06:29 +0800</pubDate><guid>https://rojeralone.cn/ostep/multiprocessor-scheduler/</guid><description>Multiprocessors Scheduling 之前讨论的都是单 CPU 上的多个任务调度，但是现代 CPU 大都是多核 CPU，多线程编程也随之出现，编程方式也和以前不一样，这里就讨论下多核调度策略。
多核带来的第一个问题是缓存的一致性问题， CPU 会缓存一些数据到 CPU 核中，多核情况下，一个任务从 A 核调度到了 B 核，那么在修改了值以后可能读到缓存的旧值，可以通过总线来解决，每个 CPU 核监听总线上的时间，当发现缓存数据对应的内存中数据变化时，标记脏数据或更新数据。
另一个问题是并发问题，最后一个问题是缓存亲缘性，一个任务最好一直在同一个 CPU 处理器上运行，这样就能使用之前的缓存了。
SQMS single-queue multiprocessor scheduling 的实现方式是将所有的任务都在同一个队列中，多处理器调度时都从这个队列中进行调度，优点是能够在之前提到的调度器上稍微修改就能运行。
缺点也很明显，多处理器消费一个队列，要加锁才能保证并发安全， 而当处理器核数很多的时候，性能就会变差。另一个问题是缓存亲缘性，这个问题也可以解决，通过忽略一些在其他处理器上运行的任务，但是实现起来比较复杂。
MQMS 很自然想到，一个任务队列有问题，那么多个任务队列呢？这就是 multi-queue multiprocessor scheduling。 它同时解决了并发和缓存亲缘性问题。
MQMS 的问题是负载均衡，当任务放到一个 CPU 核的队列内后不再变化，任务提交时任务的执行时间不可预测，会出现某个 CPU 的任务全部完成了，另一个 CPU 还要运行好久才能完成任务。
这时候就不得不放弃一些缓存亲缘性了，将一些等待执行的任务迁移到空闲的 CPU 上。一种实现机制是工作窃取，一个 CPU 上的调度器偶尔会偷看另一个 CPU 上的调度负载，如果发现另一个 CPU 比较繁忙而自己比较空闲，那么就“偷”一个或一些任务来运行。这里又有一个权衡，不能太频繁偷看，否则消耗太高，这又是一个调参找阈值的地方。
Linux Multiprocessor Schedulers Linux 的调度器没有采用统一的多队列，O(1) 和 CFS 调度器都采用了多队列，但是 BFS 调度器并没有，它采用了单队列。书中并没有详细说明这些调度器的策略，下面是维基的页面：
O(1) Scheduler BFS</description></item><item><title>OSTEP 读书笔记: 虚拟化之任务调度</title><link>https://rojeralone.cn/ostep/scheduler/</link><pubDate>Sun, 20 Jun 2021 15:33:09 +0800</pubDate><guid>https://rojeralone.cn/ostep/scheduler/</guid><description>虚拟化之 CPU 虚拟化：任务调度 工作负载假设 任务运行时间相同 任务同时到达开始运行 任务开始运行不停止直到运行结束 所有任务只需要用 CPU 运行时间已知 调度指标 平均等待时间
调度策略 FIFO，放开假设 1，导致问题：耗时长的任务先运行，一些短任务要等很久 SJF（Shortest Job First）：解决 FIFO 的弊端，放开假设 2，长任务执行时短任务来了，也要等很久 STCF（Shortest Time-to-Completion First）：放开假设 3，允许中断，可以先完成的任务先执行 现在引入新的指标，响应时间，即任务开始运行的时间减去任务到达的时间，因为操作系统会有用户直接在控制台执行命令的场景，希望立马能够有响应而不是给人系统卡住的感觉。
Round Robin 算法，轮转执行，以时钟周期的整数倍为一个时间片，每个任务轮流执行一个时间片，这样能够降低响应时间，但是完成等待时间就上去了，鱼与熊掌不可兼得。 那么放开假设 4，任务需要执行 IO，策略变更为当任务执行 IO 时，让出 CPU 给需要的任务。
在真实的系统中，运行时间是很不确定的，很难预测，应该怎么处理？下面的多级反馈队列机制将会解决这个问题。
MLFQ MLFQ (Multiple-Level Feedback Queue) 的基本原理是有多个优先级队列，优先级更高的队列里的任务优先执行，优先级相同的就轮流执行，同时还会动态调整任务的优先级。
Rule 1： A 的优先级大于 B，则 A 运行 Rule 2：A 优先级等于 B，A、B 使用 RR 运行 Rule 3：任务刚提交的时候，优先级默认为最高优先级 Rule 4a：任务运行时用光了一个完整的时间片，则降低优先级，因为它是 CPU 密集的，对响应时间不敏感 Rule 4b：用完时间片之前让出了 CPU，保持优先级不变 MLFQ 有几个问题：饥饿、投机、优先级只降不升</description></item></channel></rss>