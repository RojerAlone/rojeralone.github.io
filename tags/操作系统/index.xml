<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>操作系统 on RojerAlone</title><link>https://rojeralone.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link><description>Recent content in 操作系统 on RojerAlone</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 19 Jul 2021 23:27:08 +0800</lastBuildDate><atom:link href="https://rojeralone.cn/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml"/><item><title>OSTEP 读书笔记: 并发之锁</title><link>https://rojeralone.cn/ostep/concurrency-lock/</link><pubDate>Mon, 19 Jul 2021 23:27:08 +0800</pubDate><guid>https://rojeralone.cn/ostep/concurrency-lock/</guid><description>评估 如果评估锁的好坏？
是否能够做到互斥 公平性，避免饥饿 性能 实现方式 控制中断 最简单的实现方式，当执行需要互斥的代码时，禁止中断。
问题：
禁止中断是特权操作，普通进程能执行这个操作比较危险 多处理器时，这种方式就不管用了 关掉中断可能导致比较重要的中断无法响应，甚至导致系统崩溃 性能很差 Loads / Stores 用一个变量标识是否获取了锁，问题是，两个线程同时执行 if (flag == 0) flag = 1 这个操作，这不是个原子操作，可能会被中断，A 准备赋值为 1 时被中断了，导致另一个线程认为自己应该获取锁，那么两个线程都能获取到锁。
Test-And-Set 自旋锁 硬件提供了 Test-And-Set 指令，对某个变量设置新值的同时返回旧值，操作系统在这个指令的基础上实现锁的概念。
这个实现方式可以保证互斥，但是不能保证公平，性能也比较差，存在浪费 CPU 的情况（一直循环执行 Test-And-Set）。
另外，一些 CPU 也提供了另一种硬件支持的原语，Compare-And-Set CAS，也能实现锁。
还有其他的硬件支持的指令，比如 Fetch-And-Add
Just Yield 在自旋锁的基础上优化性能，对于没获取到锁的线程，让出自己的 CPU，然后等待已经获取锁的线程使用完后释放锁，主动唤醒正在等待的线程。
问题是，并不能解决饥饿问题，存在线程反复获取锁然后释放，导致另一些线程一直等待的问题。
等待队列 解决上一种实现方式的问题，没获取到锁的线程排队进入一个队列里，获取了锁的线程释放锁时，唤醒队列中第一个线程，避免无尽等待。需要操作系统提供支持，park() 用来让出 CPU 并睡眠，unpark(pid) 用来唤醒指定线程。
两阶段锁 进一步优化，第一阶段尝试自旋获取锁，如果在执行时间内没有获取到锁，再进入等待队列。
锁相关的数据结构 并发计数器 多个线程同时执行加法计算，由于要保证并发安全，需要加锁，那么多线程执行时的速度就很慢。理论上，多线程应该要比单线程要快，实际可能并非如此。
通过多核 CPU 同时执行，能够提升相应的性能，叫做完美扩展，比如原来单个 CPU 需要 1s 完成的任务，任务量扩大了 3 倍，3 个 CPU 同时执行，还是只需要 1s 就能完成。</description></item><item><title>OSTEP 读书笔记: 内存虚拟化之内存页</title><link>https://rojeralone.cn/ostep/virtual-memory-page/</link><pubDate>Sun, 11 Jul 2021 22:17:40 +0800</pubDate><guid>https://rojeralone.cn/ostep/virtual-memory-page/</guid><description>如果将内存以定长的分页管理，那么就能解决分段管理内存的碎片化问题，并且管理空闲内存也更方便，只需要一个空闲 page 列表，需要多大内存就分配相应个数的 page 就可以了。
为了简化虚拟内存到物理内存的映射关系，分页的大小是固定的，虚拟内存和物理内存都使用相同大小的分页。
操作系统使用页表（page table) 来表示虚拟内存到物理内存的映射，并且每个进程都有自己的页表。
每个虚拟内存页都有一个编号来表示，称为 VPN (Vitrual Page Number)，而物理内存页的编号为 PFN (Physical Frame Number) 或者 PPN (Physical Page Number)。
为了知道访问的虚拟内存是哪个页，虚拟地址需要耗费几个 bit 来表示，比如高 2 位表示 VPN，剩下的表示在内存页内的偏移量，操作系统只需要查找页表中对应的 VPN 映射的 PPN，然后访问指定偏移量的内存就行了。
页表存储 假设在 32-bit 的系统上，page 大小为 4K，那么一个进程的地址空间为 4GB，有 1M 个 page，每个 page 的数据结构 PTE (Page Table Entry) 需要 4 byte，那么每个进程需要 4MB 的内存来保存页表，1000 个进程就需要 4GB 的内存。
由于页表太大了，没法直接在 MMU 中存储，只能放在内存里(也可以放在磁盘)，那么现在的问题就是解决页表的存储问题，既要减少内存使用，又要高效查找映射关系。
PTE 中有什么？
valid bit：有效位，内存是否已经分配给进程了，没分配的不能访问 protection bit：保护位，是否可读 / 可写 / 可执行 persent bit：持久位，是否已经置换到磁盘上了 dirty bit：从磁盘加载到内存以后是否被修改过，没修改的话下次置换它就不用写磁盘了 access bit：记录访问信息，用来决定是否是热点数据，能不能被置换掉 &amp;hellip; 另一个问题就是效率，如果要访问内存，操作系统本身要解析虚拟地址对应的 VPN，然后访问页表，找到映射关系，也就是寻址这个操作中不是一步完成的，还需要另一次寻址。</description></item><item><title>OSTEP 读书笔记: 内存虚拟化之基础知识</title><link>https://rojeralone.cn/ostep/virtual-memory-basic/</link><pubDate>Wed, 23 Jun 2021 20:14:15 +0800</pubDate><guid>https://rojeralone.cn/ostep/virtual-memory-basic/</guid><description>内存虚拟化 - 基础知识 地址空间 操作系统为虚拟内存提供的抽象叫做地址空间(Address Space)，是运行中的进程能够看到的内存空间。进程申请内存主要用作 3 种数据的存储：代码、堆、栈。每个进程看到的地址空间都是一样的，给进程一种自己拥有所有内存的假象，而在真正的物理内存上，实现了进程隔离，保证了内存操作的安全性。
目标 内存虚拟化的目标：
透明 高效 保护：进程之间不能互相访问对方的内存空间 内存操作 API 一个进程会显示申请两种类型的内存，栈和堆。栈内存由编译器隐式帮程序员申请了，并且在生命周期结束后隐式释放，如果要将该内存在生命周期之外使用，则要分配堆内存，内存管理主要关注堆内存。
malloc() void *malloc(size_t size) 申请大小为 size 的内存空间，返回指向这块内存空间的指针，一般使用类型转换转化为目标类型。size 一般使用 sizeof() 操作获取，因为在不同的平台上大小可能不一样，编译器会解析 sizeof() 的结果，而不是在运行时才解析。
free() 释放内存，把 malloc 返回的指针传进去就行，内存分配器会知道释放多少内存的，不需要显示传进去。
使用注意事项 未分配内存：一些函数的指针参数是非空指针，比如 strcpy 未分配足够的内存：还是 strcpy，报错与否是不确定的 未初始化申请的内存：里边的内容是不确定的 未释放申请的内存：导致内存泄漏 提前释放了还在使用的内存：野指针 / 悬浮指针 重复释放内存：不可预知的后果，大部分是崩溃 错误调用 free(): 释放了未知的内存 系统调用 malloc() 和 free() 并不是系统调用，而是内存分配库提供的功能，这些库的底层依赖了系统调用 brk 和 sbrk，程序员不应该直接调用这些方法，除非你很清楚你在做什么，另外还可以通过 mmap 来分配内存，这是个系统调用。
内存分配库还提供一些其他调用，比如 calloc() 分配全是 0 的内存，realloc() 传入一个内存指针，返回一个更大的但是已经将旧内存 copy 过去的新内存地址。
地址转换 内存的虚拟化和 CPU 的虚拟化追求的目标一致：效率和控制。</description></item><item><title>OSTEP 读书笔记: 虚拟化之多处理器任务调度</title><link>https://rojeralone.cn/ostep/multiprocessor-scheduler/</link><pubDate>Mon, 21 Jun 2021 11:06:29 +0800</pubDate><guid>https://rojeralone.cn/ostep/multiprocessor-scheduler/</guid><description>Multiprocessors Scheduling 之前讨论的都是单 CPU 上的多个任务调度，但是现代 CPU 大都是多核 CPU，多线程编程也随之出现，编程方式也和以前不一样，这里就讨论下多核调度策略。
多核带来的第一个问题是缓存的一致性问题， CPU 会缓存一些数据到 CPU 核中，多核情况下，一个任务从 A 核调度到了 B 核，那么在修改了值以后可能读到缓存的旧值，可以通过总线来解决，每个 CPU 核监听总线上的时间，当发现缓存数据对应的内存中数据变化时，标记脏数据或更新数据。
另一个问题是并发问题，最后一个问题是缓存亲缘性，一个任务最好一直在同一个 CPU 处理器上运行，这样就能使用之前的缓存了。
SQMS single-queue multiprocessor scheduling 的实现方式是将所有的任务都在同一个队列中，多处理器调度时都从这个队列中进行调度，优点是能够在之前提到的调度器上稍微修改就能运行。
缺点也很明显，多处理器消费一个队列，要加锁才能保证并发安全， 而当处理器核数很多的时候，性能就会变差。另一个问题是缓存亲缘性，这个问题也可以解决，通过忽略一些在其他处理器上运行的任务，但是实现起来比较复杂。
MQMS 很自然想到，一个任务队列有问题，那么多个任务队列呢？这就是 multi-queue multiprocessor scheduling。 它同时解决了并发和缓存亲缘性问题。
MQMS 的问题是负载均衡，当任务放到一个 CPU 核的队列内后不再变化，任务提交时任务的执行时间不可预测，会出现某个 CPU 的任务全部完成了，另一个 CPU 还要运行好久才能完成任务。
这时候就不得不放弃一些缓存亲缘性了，将一些等待执行的任务迁移到空闲的 CPU 上。一种实现机制是工作窃取，一个 CPU 上的调度器偶尔会偷看另一个 CPU 上的调度负载，如果发现另一个 CPU 比较繁忙而自己比较空闲，那么就“偷”一个或一些任务来运行。这里又有一个权衡，不能太频繁偷看，否则消耗太高，这又是一个调参找阈值的地方。
Linux Multiprocessor Schedulers Linux 的调度器没有采用统一的多队列，O(1) 和 CFS 调度器都采用了多队列，但是 BFS 调度器并没有，它采用了单队列。书中并没有详细说明这些调度器的策略，下面是维基的页面：
O(1) Scheduler BFS</description></item><item><title>OSTEP 读书笔记: 虚拟化之任务调度</title><link>https://rojeralone.cn/ostep/scheduler/</link><pubDate>Sun, 20 Jun 2021 15:33:09 +0800</pubDate><guid>https://rojeralone.cn/ostep/scheduler/</guid><description>虚拟化之 CPU 虚拟化：任务调度 工作负载假设 任务运行时间相同 任务同时到达开始运行 任务开始运行不停止直到运行结束 所有任务只需要用 CPU 运行时间已知 调度指标 平均等待时间
调度策略 FIFO，放开假设 1，导致问题：耗时长的任务先运行，一些短任务要等很久 SJF（Shortest Job First）：解决 FIFO 的弊端，放开假设 2，长任务执行时短任务来了，也要等很久 STCF（Shortest Time-to-Completion First）：放开假设 3，允许中断，可以先完成的任务先执行 现在引入新的指标，响应时间，即任务开始运行的时间减去任务到达的时间，因为操作系统会有用户直接在控制台执行命令的场景，希望立马能够有响应而不是给人系统卡住的感觉。
Round Robin 算法，轮转执行，以时钟周期的整数倍为一个时间片，每个任务轮流执行一个时间片，这样能够降低响应时间，但是完成等待时间就上去了，鱼与熊掌不可兼得。 那么放开假设 4，任务需要执行 IO，策略变更为当任务执行 IO 时，让出 CPU 给需要的任务。
在真实的系统中，运行时间是很不确定的，很难预测，应该怎么处理？下面的多级反馈队列机制将会解决这个问题。
MLFQ MLFQ (Multiple-Level Feedback Queue) 的基本原理是有多个优先级队列，优先级更高的队列里的任务优先执行，优先级相同的就轮流执行，同时还会动态调整任务的优先级。
Rule 1： A 的优先级大于 B，则 A 运行 Rule 2：A 优先级等于 B，A、B 使用 RR 运行 Rule 3：任务刚提交的时候，优先级默认为最高优先级 Rule 4a：任务运行时用光了一个完整的时间片，则降低优先级，因为它是 CPU 密集的，对响应时间不敏感 Rule 4b：用完时间片之前让出了 CPU，保持优先级不变 MLFQ 有几个问题：饥饿、投机、优先级只降不升</description></item></channel></rss>